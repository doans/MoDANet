function lgraph = getMdl(InputSize,nofilters,filterSize)
%% Create Deep Learning Network Architecture
% Script for creating the layers for a deep learning network with the following 
% properties:
%%
% 
% nofilters = 64;
% filterSize = [9,9];
%  Number of layers: 80
%  Number of connections: 84
%
%% 
% Run the script to create the layers in the workspace variable |lgraph|.
% 
% To learn more, see <matlab:helpview('deeplearning','generate_matlab_code') 
% Generate MATLAB Code From Deep Network Designer>.
% 
% Auto-generated by MATLAB on 07-Jan-2021 21:55:13
%% Create Layer Graph
% Create the layer graph variable to contain the network layers.

lgraph = layerGraph();
%% Add Layer Branches
% Add the branches of the network to the layer graph. Each branch is a linear 
% array of layers.

tempLayers = [
    imageInputLayer(InputSize,"Name","imageinput","Mean",zeros(InputSize))
    convolution2dLayer(filterSize,nofilters,"Name","conv_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_1")
    reluLayer("Name","relu_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer(filterSize,nofilters,"Name","conv_2_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_2_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_2_1")
    reluLayer("Name","relu_2_1")
    convolution2dLayer(filterSize,nofilters,"Name","conv_3_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_4_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_3_1")
    reluLayer("Name","relu_3_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([1 1],nofilters,"Name","conv_4_1","Padding","same")
    maxPooling2dLayer([5 1],"Name","maxpool_3_1","Padding","same","Stride",[4 1])
    batchNormalizationLayer("Name","batchnorm_4_1")
    reluLayer("Name","relu_4_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = additionLayer(2,"Name","addition_1");
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer(filterSize,nofilters,"Name","conv_2_2_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_2_2_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_2_2_1")
    reluLayer("Name","relu_2_2_1")
    convolution2dLayer(filterSize,nofilters,"Name","conv_3_2_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_4_2_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_3_2_1")
    reluLayer("Name","relu_3_2_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer(filterSize,nofilters,"Name","conv_2_2_2","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_2_2_2","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_2_2_2")
    reluLayer("Name","relu_2_2_2")
    convolution2dLayer(filterSize,nofilters,"Name","conv_3_2_2","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_4_2_2","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_3_2_2")
    reluLayer("Name","relu_3_2_2")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([1 1],nofilters,"Name","conv_4_2_1","Padding","same")
    maxPooling2dLayer([5 1],"Name","maxpool_3_2_1","Padding","same","Stride",[4 1])
    batchNormalizationLayer("Name","batchnorm_4_2_1")
    reluLayer("Name","relu_4_2_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([1 1],nofilters,"Name","conv_4_2_2","Padding","same")
    maxPooling2dLayer([5 1],"Name","maxpool_3_2_2","Padding","same","Stride",[4 1])
    batchNormalizationLayer("Name","batchnorm_4_2_2")
    reluLayer("Name","relu_4_2_2")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = additionLayer(2,"Name","addition_2_1");
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([1 1],nofilters,"Name","conv_4_3_2","Padding","same")
    maxPooling2dLayer([5 1],"Name","maxpool_3_3_2","Padding","same","Stride",[4 1])
    batchNormalizationLayer("Name","batchnorm_4_3_2")
    reluLayer("Name","relu_4_3_2")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer(filterSize,nofilters,"Name","conv_2_3_2","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_2_3_2","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_2_3_2")
    reluLayer("Name","relu_2_3_2")
    convolution2dLayer(filterSize,nofilters,"Name","conv_3_3_2","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_4_3_2","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_3_3_2")
    reluLayer("Name","relu_3_3_2")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    additionLayer(2,"Name","addition_3_2")
    convolution2dLayer(filterSize,nofilters,"Name","conv_5_2","Padding","same")
    batchNormalizationLayer("Name","batchnorm_5_2")
    reluLayer("Name","relu_5_2")
    fullyConnectedLayer(121,"Name","fc_2")
    softmaxLayer("Name","softmax_2")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = additionLayer(2,"Name","addition_2_2");
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer(filterSize,nofilters,"Name","conv_2_3_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_2_3_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_2_3_1")
    reluLayer("Name","relu_2_3_1")
    convolution2dLayer(filterSize,nofilters,"Name","conv_3_3_1","Padding","same")
    maxPooling2dLayer([3 1],"Name","maxpool_4_3_1","Padding","same","Stride",[2 1])
    batchNormalizationLayer("Name","batchnorm_3_3_1")
    reluLayer("Name","relu_3_3_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    convolution2dLayer([1 1],nofilters,"Name","conv_4_3_1","Padding","same")
    maxPooling2dLayer([5 1],"Name","maxpool_3_3_1","Padding","same","Stride",[4 1])
    batchNormalizationLayer("Name","batchnorm_4_3_1")
    reluLayer("Name","relu_4_3_1")];
lgraph = addLayers(lgraph,tempLayers);

tempLayers = [
    additionLayer(2,"Name","addition_3_1")
    convolution2dLayer(filterSize,nofilters,"Name","conv_5_1","Padding","same")
    batchNormalizationLayer("Name","batchnorm_5_1")
    reluLayer("Name","relu_5_1")
    fullyConnectedLayer(12,"Name","fc_1")
    softmaxLayer("Name","softmax_1")];
lgraph = addLayers(lgraph,tempLayers);

% clean up helper variable
clear tempLayers;
%% Connect Layer Branches
% Connect all the branches of the network to create the network graph.

lgraph = connectLayers(lgraph,"relu_1","conv_2_1");
lgraph = connectLayers(lgraph,"relu_1","conv_4_1");
lgraph = connectLayers(lgraph,"relu_4_1","addition_1/in2");
lgraph = connectLayers(lgraph,"relu_3_1","addition_1/in1");
lgraph = connectLayers(lgraph,"addition_1","conv_2_2_1");
lgraph = connectLayers(lgraph,"addition_1","conv_2_2_2");
lgraph = connectLayers(lgraph,"addition_1","conv_4_2_1");
lgraph = connectLayers(lgraph,"addition_1","conv_4_2_2");
lgraph = connectLayers(lgraph,"relu_4_2_1","addition_2_1/in2");
lgraph = connectLayers(lgraph,"relu_3_2_1","addition_2_1/in1");
lgraph = connectLayers(lgraph,"addition_2_1","conv_4_3_2");
lgraph = connectLayers(lgraph,"addition_2_1","conv_2_3_2");
lgraph = connectLayers(lgraph,"relu_3_3_2","addition_3_2/in1");
lgraph = connectLayers(lgraph,"relu_3_2_2","addition_2_2/in1");
lgraph = connectLayers(lgraph,"relu_4_3_2","addition_3_2/in2");
lgraph = connectLayers(lgraph,"relu_4_2_2","addition_2_2/in2");
lgraph = connectLayers(lgraph,"addition_2_2","conv_2_3_1");
lgraph = connectLayers(lgraph,"addition_2_2","conv_4_3_1");
lgraph = connectLayers(lgraph,"relu_4_3_1","addition_3_1/in2");
lgraph = connectLayers(lgraph,"relu_3_3_1","addition_3_1/in1");
%% Plot Layers

% plot(lgraph);